{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import  Dataset,DataLoader,random_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets\n",
    "\n",
    " - Trainning dataset: https://cloud.ipb.pt/f/657d534db56645059905/?dl=1\n",
    " - Evaluate dataset: https://cloud.ipb.pt/f/27e4d3ac75d2405aa770/?dl=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset dispositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    # transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder('./train', transform=train_transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - (train_size+val_size)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# DataLoaders for train and validation\n",
    "train_loader = DataLoader(train_dataset,  batch_size=32,shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32,shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32,shuffle=False)\n",
    "\n",
    "full_dataset = DataLoader(dataset, batch_size=32,shuffle=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our CNN architecture to 64x64px image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionNeuralNetwork, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.conv2 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(24)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(48)\n",
    "        self.conv4 = nn.Conv2d(in_channels=48, out_channels=48, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(48)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.drop1=nn.Dropout(p=0.2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=48, out_channels=96, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(96)\n",
    "        self.conv6 = nn.Conv2d(in_channels=96, out_channels=96, kernel_size=4, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(96)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.fc1 = nn.Linear(96*5*5, 192)\n",
    "        self.drop2=nn.Dropout(p=0.2)\n",
    "\n",
    "        self.fc2 = nn.Linear(192, 96)\n",
    "        self.fc3 = nn.Linear(96, 1)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = F.relu(self.bn1(self.conv1(input)))      \n",
    "        output = F.relu(self.bn2(self.conv2(output)))     \n",
    "        output = self.pool1(output)  \n",
    "\n",
    "        output = F.relu(self.bn3(self.conv3(output)))      \n",
    "        output = F.relu(self.bn4(self.conv4(output)))     \n",
    "        output = self.pool2(output)      \n",
    "        output = self.drop1(output)  \n",
    "\n",
    "        output = F.relu(self.bn5(self.conv5(output)))      \n",
    "        output = F.relu(self.bn6(self.conv6(output)))  \n",
    "        output = self.pool3(output)  \n",
    "\n",
    "        output = output.reshape(output.size(0),-1)\n",
    "\n",
    "        output = F.relu(self.fc1(output))\n",
    "        output = self.drop2(output)\n",
    "        output = F.relu(self.fc2(output))\n",
    "        output = self.fc3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionNeuralNetwork()\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "        total_train_samples = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5).int()\n",
    "            train_correct += (predictions == labels).sum().item()\n",
    "            total_train_samples += labels.size(0)\n",
    "\n",
    "        avg_train_acc = train_correct / total_train_samples\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss:.4f}, AVG Training Acc: {avg_train_acc:.4f}\")\n",
    "\n",
    "        if val_loader is not None:\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            total_val_samples = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device).float().unsqueeze(1)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    predictions = (torch.sigmoid(outputs) > 0.5).int()\n",
    "                    val_correct += (predictions == labels).sum().item()\n",
    "                    total_val_samples += labels.size(0)\n",
    "\n",
    "            avg_val_acc = val_correct / total_val_samples\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "            print(f\"Validation Loss: {avg_val_loss:.4f}, AVG Validation Acc: {avg_val_acc:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15, Loss: 0.1684, AVG Training Acc: 0.9800\n",
      "Validation Loss: 1.2000, AVG Validation Acc: 0.4400\n",
      "\n",
      "Epoch 2/15, Loss: 0.0883, AVG Training Acc: 0.9850\n",
      "Validation Loss: 1.4771, AVG Validation Acc: 0.4400\n",
      "\n",
      "Epoch 3/15, Loss: 0.0694, AVG Training Acc: 0.9700\n",
      "Validation Loss: 1.0651, AVG Validation Acc: 0.4400\n",
      "\n",
      "Epoch 4/15, Loss: 0.0616, AVG Training Acc: 0.9800\n",
      "Validation Loss: 0.2196, AVG Validation Acc: 0.9200\n",
      "\n",
      "Epoch 5/15, Loss: 0.0413, AVG Training Acc: 0.9850\n",
      "Validation Loss: 0.0562, AVG Validation Acc: 1.0000\n",
      "\n",
      "Epoch 6/15, Loss: 0.0390, AVG Training Acc: 0.9850\n",
      "Validation Loss: 0.1595, AVG Validation Acc: 0.9600\n",
      "\n",
      "Epoch 7/15, Loss: 0.0533, AVG Training Acc: 0.9800\n",
      "Validation Loss: 0.0648, AVG Validation Acc: 0.9600\n",
      "\n",
      "Epoch 8/15, Loss: 0.0323, AVG Training Acc: 0.9950\n",
      "Validation Loss: 0.0894, AVG Validation Acc: 0.9200\n",
      "\n",
      "Epoch 9/15, Loss: 0.0474, AVG Training Acc: 0.9800\n",
      "Validation Loss: 0.1668, AVG Validation Acc: 0.9600\n",
      "\n",
      "Epoch 10/15, Loss: 0.0217, AVG Training Acc: 0.9900\n",
      "Validation Loss: 0.2049, AVG Validation Acc: 0.9600\n",
      "\n",
      "Epoch 11/15, Loss: 0.0736, AVG Training Acc: 0.9800\n",
      "Validation Loss: 0.0728, AVG Validation Acc: 0.9600\n",
      "\n",
      "Epoch 12/15, Loss: 0.0767, AVG Training Acc: 0.9600\n",
      "Validation Loss: 0.0884, AVG Validation Acc: 0.9600\n",
      "\n",
      "Epoch 13/15, Loss: 0.0259, AVG Training Acc: 0.9900\n",
      "Validation Loss: 0.3644, AVG Validation Acc: 0.8800\n",
      "\n",
      "Epoch 14/15, Loss: 0.0284, AVG Training Acc: 0.9900\n",
      "Validation Loss: 0.1935, AVG Validation Acc: 0.9600\n",
      "\n",
      "Epoch 15/15, Loss: 0.0347, AVG Training Acc: 0.9800\n",
      "Validation Loss: 0.1211, AVG Validation Acc: 0.9600\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=15)\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32)]\n",
      "Precision: 0.9167\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.9565\n",
      "Final F1-Score: 0.9565\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    device = torch.device('cpu')\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.numpy()  # Convert labels to CPU numpy array\n",
    "            outputs = torch.sigmoid(model(images))\n",
    "            if outputs.size(1) > 1:  # Caso haja múltiplas classes\n",
    "                preds = torch.argmax(outputs, dim=1)  # Seleciona a classe com maior probabilidade\n",
    "            else:\n",
    "                preds = (outputs > 0.5).int().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    print(all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "    return f1\n",
    "\n",
    "f1 = evaluate_model(trained_model, test_loader)\n",
    "print(f\"Final F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final train with the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.0373, AVG Training Acc 0.9880\n",
      "Epoch 2/5, Loss: 0.1307, AVG Training Acc 0.9681\n",
      "Epoch 3/5, Loss: 0.3589, AVG Training Acc 0.9363\n",
      "Epoch 4/5, Loss: 0.1765, AVG Training Acc 0.9681\n",
      "Epoch 5/5, Loss: 0.1402, AVG Training Acc 0.9602\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(trained_model, full_dataset, None, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to result.txt\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Ajuste o tamanho conforme necessário\n",
    "    transforms.ToTensor(),          # Converte as imagens para tensores\n",
    "])\n",
    "\n",
    "class ImageFolderEval(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        # Listar todas as imagens no diretório\n",
    "        self.images = [f for f in os.listdir(directory) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.directory, self.images[idx])\n",
    "        image = Image.open(img_path).convert('RGB')  # Abrir a imagem\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.images[idx]  \n",
    "\n",
    "# Carregar as imagens do diretório './eval'\n",
    "eval_dir = './eval'\n",
    "eval_dataset = ImageFolderEval(eval_dir, transform=transform)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "result_file = \"result.txt\"\n",
    "trained_model.eval()\n",
    "with open(result_file, 'w') as f:\n",
    "    for i, (images, img_names) in enumerate(eval_loader):\n",
    "        images = images.to(torch.device('cpu'))\n",
    "\n",
    "        # Fazer a previsão com o modelo\n",
    "        outputs = torch.sigmoid(trained_model(images))\n",
    "\n",
    "        # Se o modelo for multi-classe ou multi-rótulo, use o índice da classe com maior probabilidade\n",
    "        if outputs.size(1) > 1:  # Caso haja múltiplas classes\n",
    "            preds = torch.argmax(outputs, dim=1)  # Seleciona a classe com maior probabilidade\n",
    "        else:\n",
    "            preds = (outputs > 0.5).int()  # Para um único valor de saída (classificação binária)\n",
    "\n",
    "        # Iterando sobre cada previsão no batch\n",
    "        for j, (pred, img_name) in enumerate(zip(preds, img_names)):\n",
    "            f.write(f\"{img_name} {pred.item()}\\n\")\n",
    "\n",
    "print(f\"Predictions saved to {result_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
